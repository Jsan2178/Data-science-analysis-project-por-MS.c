{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc19d6d-5d57-4875-a3e3-016aaee2c317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/embed_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/embed_index.py\n",
    "#comment to test overwritting\n",
    "\n",
    "import numpy as np \n",
    "from typing import List, Tuple \n",
    "from sentence_transformers import SentenceTransformer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def load_embedding_model(name: str=\"sentence-transformers/all-MiniLM-L6-v2\") -> SentenceTransformer:\n",
    "    return SentenceTransformer(name)\n",
    "def build_embeddings(texts: List[str], model: SentenceTransformer)-> np.ndarray:\n",
    "    X= model.encode(texts, normalize_embeddings=True, show_progress_bar=True)\n",
    "    return np.asarray(X, dtype=\"float32\") #converts X elements in float32 \n",
    "\n",
    "class VectorIndex:\n",
    "    \"\"\"Simple index for cosine similarity \"\"\"\n",
    "    def __init__(self, embeddings: np.ndarray):\n",
    "        self.X = np.asarray(embeddings, dtype=\"float32\")\n",
    "        if self.X.ndim !=2:\n",
    "            raise ValueError(\"embeddings must be (n,d)\")\n",
    "    def search(self, q: np.ndarray, top_k: int=8)-> Tuple[np.ndarray, np.ndarray]:\n",
    "        q = np.asarray(q, dtype=\"float32\")\n",
    "        if q.ndim ==1: q=q[None, :] #if (d,) converts to (1,d)\n",
    "        sims= cosine_similarity(q, self.X)[0] #cosine for all corpus\n",
    "        idx = np.argsort(-sims)[:top_k]  #top-k by descendent score (-sims) because argsort order from smallest to largest\n",
    "        return idx, sims[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce0cc42-a5e7-4653-a184-ca9dbc346193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e276b51f-764e-40ce-9973-aba085cc4b90",
   "metadata": {
    "tags": []
   },
   "source": [
    "Testing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cd2aeea-8f43-41d9-8920-6d99f6bfeb71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 384)\n",
      "[[ 0.0019667   0.04314606 -0.03825914 ...  0.09706439 -0.01647028\n",
      "   0.00430816]\n",
      " [-0.00097454  0.04636284 -0.06252134 ...  0.08759326  0.02048792\n",
      "  -0.01915114]\n",
      " [ 0.02842838  0.04052663 -0.00934935 ...  0.06045973  0.07326677\n",
      "   0.03709169]\n",
      " [-0.05502563 -0.00187894 -0.02362817 ...  0.10947131  0.01036286\n",
      "  -0.01954292]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Example texts\n",
    "texts = [\n",
    "    \"El gato se sentó en la alfombra.\",\n",
    "    \"Un felino descansando sobre una alfombra suave.\",\n",
    "    \"Hoy lloverá en Monterrey según el pronóstico.\",\n",
    "    \"Recetas fáciles de pollo a la parrilla.\"\n",
    "]\n",
    "\n",
    "#2) Load model and build embbedings\n",
    "m = load_embedding_model()\n",
    "X= build_embeddings(texts, m) #(n,d)\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d737cde-245f-427f-99f2-27a9c45a3727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 35.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['Felino sobre una alfombra']\n",
      "1. Un felino descansando sobre una alfombra suave. (score= 0.867)\n",
      "2. El gato se sentó en la alfombra. (score= 0.615)\n",
      "3. Recetas fáciles de pollo a la parrilla. (score= 0.439)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#3) Build index\n",
    "index= VectorIndex(X)\n",
    "\n",
    "#4) query \n",
    "query=[\"Felino sobre una alfombra\"]\n",
    "q=build_embeddings(query, m)  #(1,d)\n",
    "\n",
    "#5) search \n",
    "I, S =index.search(q, top_k=3)\n",
    "print(\"Query:\", query)\n",
    "for rank, (i, s) in enumerate(zip(I, S), 1):\n",
    "    print(f\"{rank}. {texts[i]} (score={s: .3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
